{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Import Necessary Packages\n",
        "import os\n",
        "import bs4\n",
        "import streamlit as st\n",
        "from langchain import hub\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.schema import AIMessage ,HumanMessage ,SystemMessage\n",
        "import fitz\n",
        "from gtts import gTTS\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Your_API_KEY\""
      ],
      "metadata": {
        "id": "-MCblUsBe9j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf_file_content(file_path):\n",
        "    text_content = ''\n",
        "    with fitz.open(file_path) as doc:\n",
        "        for page in doc:\n",
        "            text_content += page.get_text()\n",
        "    return text_content\n",
        "\n",
        "# Simple document class\n",
        "class SimpleDocument:\n",
        "    def __init__(self, page_content, metadata=None):\n",
        "        self.page_content = page_content\n",
        "        self.metadata = metadata or {}\n",
        "\n",
        "# Loader class for documents\n",
        "class TextFileLoader:\n",
        "    def __init__(self, file_paths):\n",
        "        self.file_paths = file_paths\n",
        "\n",
        "    def load(self):\n",
        "        docs = []\n",
        "        for file_path in self.file_paths:\n",
        "            text_content = load_pdf_file_content(file_path)\n",
        "            docs.append(SimpleDocument(page_content=text_content))\n",
        "        return docs\n",
        "\n",
        "# Initial setup: Load PDF, process content\n",
        "loader = TextFileLoader(file_paths=(\"Azure_AI.pdf\",))  # Update path\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
        "\n",
        "class LangChainRAGChatbot:\n",
        "    def __init__(self):\n",
        "        self.retriever = vectorstore.as_retriever()\n",
        "        self.prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "        self.llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
        "        self.previous_context=\"\"\n",
        "\n",
        "    def ask_question(self, question):\n",
        "        # Combine previous context with the new question for input\n",
        "        combined_input = f\"{self.previous_context}\\nQ: {question}\\nA:\" if self.previous_context else f\"Q: {question}\\nA:\"\n",
        "\n",
        "        # Adjust the call to `invoke` to use the expected `input` parameter\n",
        "        result = self.llm.invoke(input=combined_input, max_tokens=150)\n",
        "\n",
        "        # Process the result as needed (assuming result is directly the answer text)\n",
        "        # Update the context with the new question and answer\n",
        "        self.previous_context += f\"\\nQ: {question}\\nA: {result}\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    def format_docs(self,docs):\n",
        "      return '\\n\\n'.join(doc.page_content for doc in docs)\n",
        "\n",
        "    def format_context(self,previous_context,new_question):\n",
        "      return f\"{previous_context}\\nQ: {new_question}\\nA:\"\n",
        "\n",
        "    def update_context(self,question,answer):\n",
        "      self.previous_context += f\"\\nQ: {question}\\nA: {answer}\"\n",
        "\n",
        "# Function to generate and save audio file using gTTS\n",
        "def text_to_speech(text, language, save_path='output.mp3'):\n",
        "    # gTTS for text-to-speech\n",
        "    tts = gTTS(text, lang=language, slow=False)\n",
        "    tts.save(save_path)\n",
        "    return save_path"
      ],
      "metadata": {
        "id": "mVwvnvyHpTwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot=LangChainRAGChatbot()"
      ],
      "metadata": {
        "id": "ueMwZSLgwHDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit web application\n",
        "\n",
        "def main():\n",
        "  st.title(\"Multilingual Storytelling and Text-to-Speech App\")\n",
        "\n",
        "  # User input\n",
        "  text_input=st.text_area(\"Enter the text for Multilingual Storytelling\")\n",
        "  target_language=st.selectbox(\"Select target language:\", [\"es\",\"fr\",\"de\",\"it\"])\n",
        "\n",
        "  # Storytelling button\n",
        "  if st.button('Multilingual Storytelling'):\n",
        "    if text_input:\n",
        "      story_telling=chatbot.ask_question(text_input)\n",
        "      st.subheader(\"Multilingual Storytelling\")\n",
        "      st.write(story_telling)\n",
        "\n",
        "     # Text-to-Speech button\n",
        "      if st.button('Text-to-Speech'):\n",
        "        audio_file_path= \"output_audio.mp3\"\n",
        "        text_to_speech(story_telling,target_language,audio_file_path)\n",
        "        st.audio(audio_file_path,format=\"audio/mp3\",start_time=0)\n",
        "\n",
        "        # Remove the audio file after playing\n",
        "        os.remove(audio_file_path)\n",
        "\n",
        "if __name__=='__main__':\n",
        "  main()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8SqWOy0qr7-X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}